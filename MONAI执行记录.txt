D:\ProgramData\Anaconda3\envs\MONAI\python.exe "D:\Program Files\JetBrains\PyCharm 2021.2.1\plugins\python\helpers\pydev\pydevd.py" --multiproc --qt-support=auto --client 127.0.0.1 --port 51336 --file D:/Desktop/MONAI/3d_segmentation/brats_segmentation_3d.py
Connected to pydev debugger (build 212.5080.64)
tempdir: C:\Users\10099\AppData\Local\Temp\tmpm_s7crt7
D:\Desktop\MONAI_DATA_DIRECTORY
MONAI version: 0.8.1+124.gbcbfbddc
Numpy version: 1.21.5
Pytorch version: 1.6.0
MONAI flags: HAS_EXT = False, USE_COMPILED = False
MONAI rev id: bcbfbddc359a88bfa51a98ae2b07344066484310
MONAI __file__: D:\Desktop\MONAI\monai\__init__.py
Optional dependencies:
Pytorch Ignite version: 0.4.8
Nibabel version: 3.2.2
scikit-image version: 0.19.2
Pillow version: 9.0.1
Tensorboard version: 2.8.0
gdown version: 4.3.0
TorchVision version: 0.7.0
tqdm version: 4.62.3
lmdb version: 1.3.0
psutil version: 5.9.0
pandas version: 1.3.5
einops version: 0.4.0
transformers version: 4.16.2
mlflow version: 1.23.1
For details about installing the optional dependencies, please visit:
    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies
2022-03-31 14:27:46,882 - INFO - Verified 'Task01_BrainTumour.tar', md5: 240a19d752f0d9e9101544901065d872.
2022-03-31 14:27:46,882 - INFO - File exists: D:\Desktop\MONAI_DATA_DIRECTORY\Task01_BrainTumour.tar, skipped downloading.
2022-03-31 14:27:46,890 - INFO - Non-empty folder exists in D:\Desktop\MONAI_DATA_DIRECTORY\Task01_BrainTumour, skipped extracting.
image shape: torch.Size([4, 240, 240, 155])
label shape: torch.Size([3, 240, 240, 155])
----------
epoch 1/300
1/388, train_loss: 0.8500, step time: 5.7507
2/388, train_loss: 0.9932, step time: 0.7263
3/388, train_loss: 1.0000, step time: 0.7122
4/388, train_loss: 0.9671, step time: 0.7312
5/388, train_loss: 0.9410, step time: 0.7308
6/388, train_loss: 0.8702, step time: 0.7241
7/388, train_loss: 0.8268, step time: 0.7218
8/388, train_loss: 0.6935, step time: 0.7308
9/388, train_loss: 0.8740, step time: 0.7291
10/388, train_loss: 0.9950, step time: 0.7296
11/388, train_loss: 0.7497, step time: 0.7231
12/388, train_loss: 0.9834, step time: 0.7326
13/388, train_loss: 1.0000, step time: 0.7087
14/388, train_loss: 0.9999, step time: 0.7181
15/388, train_loss: 0.9873, step time: 0.7274
16/388, train_loss: 0.9681, step time: 0.7289
17/388, train_loss: 0.9724, step time: 0.7423
18/388, train_loss: 0.6717, step time: 0.7491
19/388, train_loss: 0.7602, step time: 0.7233
20/388, train_loss: 0.9568, step time: 0.7425
21/388, train_loss: 0.7000, step time: 0.7478
22/388, train_loss: 0.8273, step time: 0.7387
23/388, train_loss: 0.9897, step time: 0.7386
24/388, train_loss: 0.8779, step time: 0.7386
25/388, train_loss: 0.8859, step time: 0.7503
26/388, train_loss: 0.6805, step time: 0.7405
27/388, train_loss: 0.7520, step time: 0.7504
28/388, train_loss: 0.6257, step time: 0.7322
29/388, train_loss: 0.9838, step time: 0.7303
30/388, train_loss: 0.7363, step time: 0.7399
31/388, train_loss: 0.7919, step time: 0.7397
32/388, train_loss: 0.6726, step time: 0.7380
33/388, train_loss: 0.8745, step time: 0.7554
34/388, train_loss: 0.8048, step time: 0.7772
35/388, train_loss: 0.8153, step time: 0.7491
36/388, train_loss: 0.5837, step time: 0.7471
37/388, train_loss: 0.5579, step time: 0.7310
38/388, train_loss: 0.9737, step time: 0.7301
39/388, train_loss: 0.9908, step time: 0.7603
40/388, train_loss: 0.7212, step time: 0.7872
41/388, train_loss: 0.9356, step time: 0.7622
42/388, train_loss: 0.7964, step time: 0.7314
43/388, train_loss: 0.7709, step time: 0.7504
44/388, train_loss: 0.8946, step time: 0.7739
45/388, train_loss: 0.8531, step time: 0.7601
46/388, train_loss: 1.0000, step time: 0.7340
47/388, train_loss: 0.9449, step time: 0.7475
48/388, train_loss: 0.9884, step time: 0.7587
49/388, train_loss: 0.9391, step time: 0.7494
50/388, train_loss: 0.7454, step time: 0.7294
51/388, train_loss: 0.9679, step time: 0.7467
52/388, train_loss: 0.8092, step time: 0.7839
53/388, train_loss: 0.8775, step time: 0.7724
54/388, train_loss: 0.7501, step time: 0.7694
55/388, train_loss: 0.9654, step time: 0.7730
56/388, train_loss: 0.7726, step time: 0.7677
57/388, train_loss: 0.7305, step time: 0.7286
58/388, train_loss: 0.9597, step time: 0.7419
59/388, train_loss: 0.8576, step time: 0.7410
60/388, train_loss: 0.7387, step time: 0.7397
61/388, train_loss: 0.8197, step time: 0.7396
62/388, train_loss: 0.8912, step time: 0.7490
63/388, train_loss: 0.9871, step time: 0.7529
64/388, train_loss: 1.0000, step time: 0.7387
65/388, train_loss: 0.8767, step time: 0.7403
66/388, train_loss: 1.0000, step time: 0.7215
67/388, train_loss: 0.9806, step time: 0.7378
68/388, train_loss: 0.6003, step time: 0.7503
69/388, train_loss: 0.7271, step time: 0.7418
70/388, train_loss: 0.9856, step time: 0.7302
71/388, train_loss: 0.9215, step time: 0.7413
72/388, train_loss: 0.9941, step time: 0.7422
73/388, train_loss: 0.7743, step time: 0.7470
74/388, train_loss: 0.7242, step time: 0.7544
75/388, train_loss: 0.6615, step time: 0.7528
76/388, train_loss: 0.7324, step time: 0.7677
77/388, train_loss: 0.9151, step time: 0.7547
78/388, train_loss: 0.9268, step time: 0.7509
79/388, train_loss: 0.9395, step time: 0.7412
80/388, train_loss: 0.6609, step time: 0.7296
81/388, train_loss: 0.8348, step time: 0.7298
82/388, train_loss: 0.6378, step time: 0.7379
83/388, train_loss: 0.5571, step time: 0.7303
84/388, train_loss: 0.6606, step time: 0.7317
85/388, train_loss: 1.0000, step time: 0.7288
86/388, train_loss: 0.9051, step time: 0.7406
87/388, train_loss: 1.0000, step time: 0.7192
88/388, train_loss: 1.0000, step time: 0.7117
89/388, train_loss: 0.8346, step time: 0.7319
90/388, train_loss: 0.7487, step time: 0.7314
91/388, train_loss: 0.9207, step time: 0.7419
92/388, train_loss: 0.7985, step time: 0.7332
93/388, train_loss: 0.9996, step time: 0.8112
94/388, train_loss: 1.0000, step time: 0.7736
95/388, train_loss: 0.9206, step time: 0.7719
96/388, train_loss: 0.8514, step time: 0.7968
97/388, train_loss: 0.8982, step time: 0.8096
98/388, train_loss: 0.7995, step time: 0.7466
99/388, train_loss: 0.6455, step time: 0.7669
100/388, train_loss: 0.9818, step time: 0.7585
101/388, train_loss: 0.8924, step time: 0.7510
102/388, train_loss: 0.9997, step time: 0.7362
103/388, train_loss: 0.7524, step time: 0.7699
104/388, train_loss: 0.9057, step time: 0.7357
105/388, train_loss: 0.9574, step time: 0.7646
106/388, train_loss: 0.9424, step time: 0.7357
107/388, train_loss: 0.7376, step time: 0.7336
108/388, train_loss: 0.6848, step time: 0.7547
109/388, train_loss: 0.6935, step time: 0.7664
110/388, train_loss: 0.7077, step time: 0.7832
111/388, train_loss: 0.9999, step time: 0.7508
112/388, train_loss: 0.9631, step time: 0.7698
113/388, train_loss: 0.9870, step time: 0.7334
114/388, train_loss: 0.7770, step time: 0.7317
115/388, train_loss: 0.8799, step time: 0.7382
116/388, train_loss: 0.9988, step time: 0.7326
117/388, train_loss: 0.8123, step time: 0.7330
118/388, train_loss: 0.7344, step time: 0.7373
119/388, train_loss: 0.5211, step time: 0.7374
120/388, train_loss: 0.9149, step time: 0.7347
121/388, train_loss: 0.9992, step time: 0.7276
122/388, train_loss: 0.7707, step time: 0.7362
123/388, train_loss: 0.8051, step time: 0.7331
124/388, train_loss: 0.9343, step time: 0.7357
125/388, train_loss: 0.8094, step time: 0.7334
126/388, train_loss: 0.8753, step time: 0.7382
127/388, train_loss: 0.6995, step time: 0.7371
128/388, train_loss: 0.9031, step time: 0.7352
129/388, train_loss: 0.5956, step time: 0.7337
130/388, train_loss: 0.7677, step time: 0.7351
131/388, train_loss: 0.8909, step time: 0.7346
132/388, train_loss: 0.8543, step time: 0.7342
133/388, train_loss: 0.6484, step time: 0.7328
134/388, train_loss: 0.8351, step time: 0.7340
135/388, train_loss: 0.6664, step time: 0.7339
136/388, train_loss: 0.9997, step time: 0.7311
137/388, train_loss: 0.5788, step time: 0.7344
138/388, train_loss: 0.9666, step time: 0.7347
139/388, train_loss: 0.6429, step time: 0.7342
140/388, train_loss: 0.8555, step time: 0.7332
141/388, train_loss: 0.7709, step time: 0.7323
142/388, train_loss: 0.7418, step time: 0.7363
143/388, train_loss: 0.7808, step time: 0.7351
144/388, train_loss: 0.8764, step time: 0.7357
145/388, train_loss: 0.9514, step time: 0.7323
146/388, train_loss: 1.0000, step time: 0.7178
147/388, train_loss: 0.6912, step time: 0.7351
148/388, train_loss: 1.0000, step time: 0.7167
149/388, train_loss: 0.8297, step time: 0.7344
150/388, train_loss: 0.7765, step time: 0.7336
151/388, train_loss: 0.5669, step time: 0.7350
152/388, train_loss: 0.5791, step time: 0.7371
153/388, train_loss: 0.6483, step time: 0.7315
154/388, train_loss: 0.8368, step time: 0.7326
155/388, train_loss: 0.8292, step time: 0.7330
156/388, train_loss: 0.6282, step time: 0.7357
157/388, train_loss: 0.8243, step time: 0.7326
158/388, train_loss: 0.8596, step time: 0.7347
159/388, train_loss: 0.6834, step time: 0.7350
160/388, train_loss: 0.7350, step time: 0.7336
161/388, train_loss: 0.7631, step time: 0.7349
162/388, train_loss: 0.9972, step time: 0.7308
163/388, train_loss: 1.0000, step time: 0.7173
164/388, train_loss: 0.7027, step time: 0.7309
165/388, train_loss: 0.6710, step time: 0.7395
166/388, train_loss: 0.6973, step time: 0.7352
167/388, train_loss: 0.9477, step time: 0.7332
168/388, train_loss: 0.7989, step time: 0.7388
169/388, train_loss: 0.9460, step time: 0.7388
170/388, train_loss: 0.9783, step time: 0.7358
171/388, train_loss: 0.9946, step time: 0.7375
172/388, train_loss: 0.7356, step time: 0.7334
173/388, train_loss: 0.7307, step time: 0.7383
174/388, train_loss: 0.7080, step time: 0.7335
175/388, train_loss: 0.4908, step time: 0.7343
176/388, train_loss: 0.6628, step time: 0.7312
177/388, train_loss: 0.7002, step time: 0.7358
178/388, train_loss: 0.6654, step time: 0.7352
179/388, train_loss: 0.9866, step time: 0.7322
180/388, train_loss: 0.6679, step time: 0.7301
181/388, train_loss: 1.0000, step time: 0.7198
182/388, train_loss: 0.9662, step time: 0.7354
183/388, train_loss: 0.9460, step time: 0.7352
184/388, train_loss: 0.6972, step time: 0.7336
185/388, train_loss: 0.7117, step time: 0.7371
186/388, train_loss: 0.9967, step time: 0.7332
187/388, train_loss: 0.6680, step time: 0.7393
188/388, train_loss: 0.8896, step time: 0.7312
189/388, train_loss: 0.8950, step time: 0.7398
190/388, train_loss: 0.6885, step time: 0.7311
191/388, train_loss: 0.6796, step time: 0.7358
192/388, train_loss: 0.9640, step time: 0.7344
193/388, train_loss: 0.9953, step time: 0.7347
194/388, train_loss: 0.7722, step time: 0.7343
195/388, train_loss: 0.7643, step time: 0.7382
196/388, train_loss: 0.6793, step time: 0.7317
197/388, train_loss: 0.7674, step time: 0.7377
198/388, train_loss: 0.9217, step time: 0.7361
199/388, train_loss: 0.7477, step time: 0.7322
200/388, train_loss: 0.7291, step time: 0.7358
201/388, train_loss: 0.9945, step time: 0.7337
202/388, train_loss: 0.7514, step time: 0.7337
203/388, train_loss: 0.9780, step time: 0.7348
204/388, train_loss: 0.8527, step time: 0.7361
205/388, train_loss: 1.0000, step time: 0.7198
206/388, train_loss: 0.9999, step time: 0.7276
207/388, train_loss: 0.7666, step time: 0.7328
208/388, train_loss: 0.9937, step time: 0.7329
209/388, train_loss: 0.6955, step time: 0.7371
210/388, train_loss: 0.7595, step time: 0.7613
211/388, train_loss: 0.8881, step time: 0.7491
212/388, train_loss: 0.6674, step time: 0.7855
213/388, train_loss: 0.8935, step time: 0.8238
214/388, train_loss: 0.7851, step time: 0.7603
215/388, train_loss: 0.8789, step time: 0.7375
216/388, train_loss: 0.7764, step time: 0.7404
217/388, train_loss: 0.8117, step time: 0.7354
218/388, train_loss: 0.9009, step time: 0.8147
219/388, train_loss: 0.6002, step time: 0.8006
220/388, train_loss: 0.7510, step time: 0.7805
221/388, train_loss: 0.9996, step time: 0.7350
222/388, train_loss: 0.8914, step time: 0.7387
223/388, train_loss: 1.0000, step time: 0.7282
224/388, train_loss: 0.9781, step time: 0.7601
225/388, train_loss: 1.0000, step time: 0.7611
226/388, train_loss: 0.9925, step time: 0.7783
227/388, train_loss: 0.9643, step time: 0.7644
228/388, train_loss: 0.7891, step time: 0.7627
229/388, train_loss: 0.9985, step time: 0.7424
230/388, train_loss: 0.8176, step time: 0.7502
231/388, train_loss: 0.8697, step time: 0.7596
232/388, train_loss: 0.7767, step time: 0.7671
233/388, train_loss: 0.8551, step time: 0.7459
234/388, train_loss: 0.8747, step time: 0.7371
235/388, train_loss: 0.6417, step time: 0.7405
236/388, train_loss: 0.9486, step time: 0.7570
237/388, train_loss: 0.7279, step time: 0.7326
238/388, train_loss: 0.8724, step time: 0.7487
239/388, train_loss: 0.7522, step time: 0.7543
240/388, train_loss: 0.6203, step time: 0.7781
241/388, train_loss: 0.9978, step time: 0.7476
242/388, train_loss: 0.9251, step time: 0.7449
243/388, train_loss: 0.9290, step time: 0.7493
244/388, train_loss: 0.8692, step time: 0.7527
245/388, train_loss: 0.7776, step time: 0.7742
246/388, train_loss: 0.9665, step time: 0.7790
247/388, train_loss: 0.5748, step time: 0.7699
248/388, train_loss: 0.8925, step time: 0.7502
249/388, train_loss: 0.7105, step time: 0.7449
250/388, train_loss: 0.6852, step time: 0.7598
251/388, train_loss: 0.5573, step time: 0.7404
252/388, train_loss: 0.8848, step time: 0.7560
253/388, train_loss: 0.5408, step time: 0.7546
254/388, train_loss: 0.7620, step time: 0.7654
255/388, train_loss: 0.8696, step time: 0.7578
256/388, train_loss: 0.7637, step time: 0.7403
257/388, train_loss: 0.9558, step time: 0.7606
258/388, train_loss: 1.0000, step time: 0.7457
259/388, train_loss: 0.9053, step time: 0.7440
260/388, train_loss: 0.9807, step time: 0.7460
261/388, train_loss: 0.7831, step time: 0.7541
262/388, train_loss: 0.7339, step time: 0.7549
263/388, train_loss: 0.8741, step time: 0.7330
264/388, train_loss: 0.7753, step time: 0.7531
265/388, train_loss: 1.0000, step time: 0.7390
266/388, train_loss: 0.9835, step time: 0.7689
267/388, train_loss: 0.6537, step time: 0.7518
268/388, train_loss: 1.0000, step time: 0.7385
269/388, train_loss: 0.6356, step time: 0.7427
270/388, train_loss: 0.9223, step time: 0.7430
271/388, train_loss: 0.9111, step time: 0.7377
272/388, train_loss: 0.9312, step time: 0.7359
273/388, train_loss: 0.9988, step time: 0.7339
274/388, train_loss: 0.7802, step time: 0.7521
275/388, train_loss: 1.0000, step time: 0.7525
276/388, train_loss: 0.9860, step time: 0.7443
277/388, train_loss: 1.0000, step time: 0.7494
278/388, train_loss: 1.0000, step time: 0.7469
279/388, train_loss: 0.9997, step time: 0.7288
280/388, train_loss: 1.0000, step time: 0.7160
281/388, train_loss: 0.6824, step time: 0.7808
282/388, train_loss: 0.8772, step time: 0.7616
283/388, train_loss: 0.8533, step time: 0.7340
284/388, train_loss: 0.7572, step time: 0.7753
285/388, train_loss: 0.6367, step time: 0.7476
286/388, train_loss: 0.9999, step time: 0.7381
287/388, train_loss: 0.5949, step time: 0.7362
288/388, train_loss: 1.0000, step time: 0.7170
289/388, train_loss: 0.9023, step time: 0.7487
290/388, train_loss: 0.9147, step time: 0.7655
291/388, train_loss: 0.9079, step time: 0.7641
292/388, train_loss: 0.9788, step time: 0.7467
293/388, train_loss: 0.9416, step time: 0.7413
294/388, train_loss: 0.5737, step time: 0.7480
295/388, train_loss: 0.7253, step time: 0.7399
296/388, train_loss: 0.7312, step time: 0.7381
297/388, train_loss: 0.6642, step time: 0.7773
298/388, train_loss: 0.7579, step time: 0.7420
299/388, train_loss: 0.8839, step time: 0.7519
300/388, train_loss: 0.8087, step time: 0.7378
301/388, train_loss: 0.4879, step time: 0.7490
302/388, train_loss: 0.6585, step time: 0.7354
303/388, train_loss: 0.6095, step time: 0.8309
304/388, train_loss: 0.6818, step time: 0.8703
305/388, train_loss: 0.8658, step time: 0.7738
306/388, train_loss: 0.8416, step time: 0.7460
307/388, train_loss: 0.6345, step time: 0.7610
308/388, train_loss: 0.6894, step time: 0.7798
309/388, train_loss: 0.6689, step time: 0.7423
310/388, train_loss: 0.7184, step time: 0.7428
311/388, train_loss: 0.9976, step time: 0.8002
312/388, train_loss: 0.9342, step time: 0.7459
313/388, train_loss: 0.7112, step time: 0.7379
314/388, train_loss: 1.0000, step time: 0.7138
315/388, train_loss: 1.0000, step time: 0.7253
316/388, train_loss: 0.9999, step time: 0.7227
317/388, train_loss: 0.6621, step time: 0.7377
318/388, train_loss: 1.0000, step time: 0.7148
319/388, train_loss: 0.6755, step time: 0.7531
320/388, train_loss: 0.7525, step time: 0.7355
321/388, train_loss: 0.6958, step time: 0.7377
322/388, train_loss: 0.9997, step time: 0.7277
323/388, train_loss: 0.6475, step time: 0.7400
324/388, train_loss: 0.6584, step time: 0.7351
325/388, train_loss: 0.8179, step time: 0.7348
326/388, train_loss: 0.7590, step time: 0.7380
327/388, train_loss: 0.7377, step time: 0.7329
328/388, train_loss: 0.7781, step time: 0.7371
329/388, train_loss: 0.9629, step time: 0.7361
330/388, train_loss: 0.9238, step time: 0.7314
331/388, train_loss: 0.9992, step time: 0.7307
332/388, train_loss: 0.7493, step time: 0.7399
333/388, train_loss: 0.7349, step time: 0.7327
334/388, train_loss: 0.6042, step time: 0.7325
335/388, train_loss: 0.8366, step time: 0.7348
336/388, train_loss: 0.9903, step time: 0.7330
337/388, train_loss: 0.9288, step time: 0.7370
338/388, train_loss: 0.8552, step time: 0.7317
339/388, train_loss: 0.7974, step time: 0.7353
340/388, train_loss: 0.6442, step time: 0.7370
341/388, train_loss: 0.8099, step time: 0.7348
342/388, train_loss: 0.6830, step time: 0.7309
343/388, train_loss: 0.8077, step time: 0.7349
344/388, train_loss: 0.8658, step time: 0.7358
345/388, train_loss: 0.6259, step time: 0.7321
346/388, train_loss: 0.9708, step time: 0.7342
347/388, train_loss: 0.7177, step time: 0.7350
348/388, train_loss: 0.5237, step time: 0.7350
349/388, train_loss: 0.7066, step time: 0.7332
350/388, train_loss: 0.6869, step time: 0.7369
351/388, train_loss: 0.7839, step time: 0.7322
352/388, train_loss: 0.9838, step time: 0.7359
353/388, train_loss: 0.8201, step time: 0.7334
354/388, train_loss: 0.9740, step time: 0.7379
355/388, train_loss: 0.7729, step time: 0.7357
356/388, train_loss: 1.0000, step time: 0.7300
357/388, train_loss: 0.9174, step time: 0.7340
358/388, train_loss: 0.8874, step time: 0.7344
359/388, train_loss: 1.0000, step time: 0.7158
360/388, train_loss: 0.8423, step time: 0.7389
361/388, train_loss: 0.7990, step time: 0.7331
362/388, train_loss: 0.7374, step time: 0.7361
363/388, train_loss: 0.8441, step time: 0.7331
364/388, train_loss: 0.8221, step time: 0.7352
365/388, train_loss: 0.9747, step time: 0.7330
366/388, train_loss: 0.6572, step time: 0.7347
367/388, train_loss: 0.7686, step time: 0.7360
368/388, train_loss: 0.6703, step time: 0.7328
369/388, train_loss: 0.5514, step time: 0.7303
370/388, train_loss: 0.8371, step time: 0.7323
371/388, train_loss: 0.6857, step time: 0.7406
372/388, train_loss: 0.6415, step time: 0.7377
373/388, train_loss: 0.6795, step time: 0.7325
374/388, train_loss: 0.8425, step time: 0.7366
375/388, train_loss: 0.7799, step time: 0.7362
376/388, train_loss: 0.6981, step time: 0.7360
377/388, train_loss: 0.9530, step time: 0.7387
378/388, train_loss: 0.9787, step time: 0.7352
379/388, train_loss: 1.0000, step time: 0.7141
380/388, train_loss: 0.9231, step time: 0.7329
381/388, train_loss: 0.6056, step time: 0.7333
382/388, train_loss: 0.8958, step time: 0.7330
383/388, train_loss: 0.8486, step time: 0.7299
384/388, train_loss: 0.9377, step time: 0.7304
385/388, train_loss: 0.9027, step time: 0.7307
386/388, train_loss: 0.8325, step time: 0.7314
387/388, train_loss: 0.7979, step time: 0.7324
388/388, train_loss: 0.6981, step time: 0.7291
epoch 1 average loss: 0.8286
saved new best metric model
current epoch: 1 current mean dice: 0.3261 tc: 0.2829 wt: 0.6857 et: 0.0096
best mean dice: 0.3261 at epoch: 1
time consuming of epoch 1 is: 823.2740
----------